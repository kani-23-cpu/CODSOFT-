import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler

LOAD DATASET
# Load the Iris dataset
iris = pd.read_csv('/kaggle/input/iris-flower-dataset/IRIS.csv')

iris.head()

Species = iris['species'].value_counts().reset_index()
Species

plt.figure(figsize=(8,8))
plt.pie(Species['count'],labels=['Iris-setosa','Iris-versicolor','Iris-virginica'],autopct='%1.3f%%',explode=[0,0,0])
plt.legend(loc='upper left')
plt.show()

#Scatter plot of different species
sns.FacetGrid(iris, hue ='species', height = 4).map(plt.scatter,"petal_length","sepal_width").add_legend()
plt.show()

CHECKING MISSING VALUES

iris.isnull().sum()

iris['species'].value_counts()

Target Variable Splitting
# Split data to be used in the models
# Create matrix of features
x = iris.drop('species', axis = 1) # grabs everything else but 'Price'

# Create target variable
y = iris['species'] # y is the column we're trying to predict

# Standardize the features
scaler = StandardScaler().fit(x)
x_transform = scaler.transform(x)

label encoder
# import labelencoder from sklearn
from sklearn.preprocessing import LabelEncoder

# Encode the target variable
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# One-hot encode the target labels
y_onehot = tf.keras.utils.to_categorical(y_encoded)

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x_transform, y_onehot, test_size=0.10, random_state=101)

# Define the input size for each data sample
input_size = x_train.shape[1]

iris.shape

MODELING

# Define the input size for each data sample (e.g., image pixels)
input_size = 4

# Specify the number of data samples to process in each batch
batch_size = 10

# Define the number of neurons in the first hidden layer
hidden1 = 100

# Define the number of neurons in the second hidden layer
hidden2 = 50


# Define the total number of classes/categories in the dataset
classes = 3

# Set the number of complete passes through the dataset during training
epochs = 70

Building the FCN Model

### 4. Build the model ###

# Create a Sequential model, which allows us to build a neural network layer by layer
model = Sequential()

# Add the first hidden layer with 'hidden1' neurons, using ReLU activation function
# The 'input_dim' specifies the input size for this layer
model.add(Dense(hidden1, input_dim=input_size, activation='relu'))
# output = relu(dot(W, input) + bias)

# Add the second hidden layer with 'hidden2' neurons, also using ReLU activation function
model.add(Dense(hidden2, activation='relu'))


# Add the output layer with 'classes' neurons, using softmax activation function
# Softmax activation ensures that the output values represent probabilities of each class
model.add(Dense(classes, activation='softmax'))

### Compilation ###

train a model

# Train the model
model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)

Evaluate the model
# Evaluate the model
loss, accuracy = model.evaluate(x_test, y_test, verbose=1)
print(f'Test Accuracy: {accuracy:.4f}')
